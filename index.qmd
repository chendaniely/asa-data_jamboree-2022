---
title: "Data Jamboree"
subtitle: "Python"
author: "Daniel Chen"
format:
  revealjs: 
    theme: simple
    footer: "[Daniel Chen](https://daniel.rbind.io/). @chendaniely. Using [Quarto](https://quarto.org/docs/presentations/revealjs/index.html). Slides: [https://github.com/chendaniely/asa-data_jamboree-2022](https://github.com/chendaniely/asa-data_jamboree-2022)"
    slide-number: c/t
    show-slide-number: all
    hash-type: number
execute: 
  echo: true
jupyter: python3
---

# Exercises

## The Questions {.smaller}

1. Create a frequency table of the number of crashes by borough.
2. Create an `hour` variable with integer values from 0 to 23, and plot of the histogram of crashes by hour.
3. Check if the number of persons killed is the summation of the number of pedestrians killed, cyclist killed, and motorists killed. From now on, use the number of persons killed as the sum of the pedestrians, cyclists, and motorists killed.
4. Construct a cross table for the number of persons killed by the contributing factors of vehicle one. Collapse the contributing factors with a count of less than 100 to “other”. Is there any association between the contributing factors and the number of persons killed?
5. Create a new variable death which is one if the number of persons killed is 1 or more; and zero otherwise. Construct a cross table for death versus borough. Test the null hypothesis that the two variables are not associated.

## The Questions {.smaller}

6. Visualize the crashes using their latitude and longitude (and time, possibly in an animation).
7. Fit a logistic model with death as the outcome variable and covariates that are available in the data or can be engineered from the data. Example covariates are crash hour, borough, number of vehicles involved, etc. Interpret your results.
8. Aggregate the data to the zip-code level and connect with the census data at the zip-code level.
9. Visualize ~~and model~~ the count of crashes at the zip-code level.

# Question 0: The Data

## Load {.smaller}

```{python}
import pandas as pd

#jan22 = pd.read_csv("https://raw.githubusercontent.com/statds/ids-s22/main/notes/data/nyc_mv_collisions_202201.csv") 
#jan22.to_csv("data/nyc_mv_collisions_202201.csv", index=False)
jan22 = pd.read_csv("data/nyc_mv_collisions_202201.csv")

jan22.head()
```

## Process {.smaller}

```{python}
import janitor

jan22 = janitor.clean_names(jan22)
jan22.head()
```

## Initial Overview

```{python}
jan22.info()
```

# Question 1

## Create a frequency table of the number of crashes by borough


```{python}
jan22["borough"].value_counts(dropna=False)
```

# Question 2

## 2a: Create an `hour` variable with integer values from 0 to 2


```{python}
jan22 = (
  jan22
  .assign(hour=jan22["crash_time"].str.split(":").str.get(0))
)
jan22[["crash_time", "hour"]].head()
```

## 2b: Plot of the histogram of crashes by hour


```{python}
from plotnine import ggplot, aes, geom_histogram

ggplot(jan22, aes(x="hour")) + geom_histogram()
```

## It's a string!

```{python}
jan22 = jan22.assign(hour_int=pd.to_numeric(jan22["hour"]))
jan22.info()
```

## Re-plot histogram

```{python}
ggplot(jan22, aes(x="hour_int")) + geom_histogram()
```


# Question 3

## Check if the number of persons killed
is the summation of the number of pedestrians killed, cyclist killed, and motorists killed.

From now on, use the number of persons killed as the sum of the pedestrians, cyclists, and motorists killed

```{python}
jan22.columns
```

## Subset the columns of interest {.smaller}


```{python}
casualty_columns = [
  'number_of_pedestrians_killed',
  'number_of_cyclist_killed',
  'number_of_motorist_killed',
]

killed = jan22[casualty_columns]
killed.head()
```

## Sum the columns


```{python}
killed_sum = killed.apply(sum, axis=1)
killed_sum.value_counts(dropna=False)
```


```{python}
jan22["number_of_persons_killed"].value_counts(dropna=False)
```

# Question 4

## 4a: Construct a cross table for the number of persons killed {.smaller}
by the contributing factors of vehicle one.

```{python}
cross_tab = pd.crosstab(
  jan22["contributing_factor_vehicle_1"],
  jan22["number_of_persons_killed"],
  margins=True
)

cross = cross_tab.reset_index()
```

## {.smaller}

```{python}
cross
```

## 4b: Collapse the contributing factors with a count of less than 100 to “other”.

```{python}
type(cross)
```

```{python}
import numpy as np

@np.vectorize
def recode_factors(factor, count):
  if count < 100:
    return "other"
  else:
    return factor
```

```{python}
recode_factors("Accelerator Defective", 9)
```

```{python}
recode_factors("Traffic Control Disregarded", 206)
```

##

```{python}
recode_factors(cross["contributing_factor_vehicle_1"], cross["All"])
```

##

```{python}
cross["recode"] = recode_factors(cross["contributing_factor_vehicle_1"], cross["All"])
cross
```

##

```{python}
recoded_cross = cross["recode"].value_counts()
recoded_cross
```

## Recode original values

```{python}
recode_dict = dict(zip(cross["contributing_factor_vehicle_1"], cross["recode"]))
recode_dict
```

##

```{python}
jan22["cont_factor_1_recode"] = jan22.contributing_factor_vehicle_1.replace(recode_dict)

jan22[["contributing_factor_vehicle_1", "cont_factor_1_recode"]]
```


## Is there any association between the contributing factors and the number of persons killed? {.smaller}


```{python}
cross_tab_recoded = pd.crosstab(
  jan22["cont_factor_1_recode"],
  jan22["number_of_persons_killed"],
  dropna=False,
  margins=True
)
cross_tab_recoded = cross_tab_recoded.reset_index()
```

## {.smaller}

```{python}
cross_tab_recoded
```

# Question 5

## 5a: Create a new variable death
which is one if the number of persons killed is 1 or more; and zero otherwise.

```{python}
def recode_num_killed(num_killed):
    if num_killed > 1:
      return 1
    else:
      return 0
```

```{python}
# TODO: this is wrong
cross_tab_recoded["death"] = cross_tab_recoded[1].apply(recode_num_killed)
```

## {.smaller}

```{python}
cross_tab_recoded
```


## 5b: Construct a cross table for death versus borough.

```{python}
death_recode = dict(zip(cross_tab_recoded["cont_factor_1_recode"], cross_tab_recoded["death"]))
death_recode
```

##

```{python}
jan22["death"] = jan22["cont_factor_1_recode"].replace(death_recode)

jan22[["cont_factor_1_recode", "death"]]
```

##

```{python}
pd.crosstab(jan22["borough"], jan22["death"])
```


## 5c: Test the null hypothesis that the two variables are not associated

```{python}
# TODO: fix model
import statsmodels.api as sm

jan22_boro_death = jan22[["borough", "death"]].dropna()
```

# Question 6

## Visualize the crashes
using their latitude and longitude (and time, possibly in an animation).


```{python}
# TODO: i don't know how to plot in python
```

# Question 7

## Fit a logistic model
with death as the outcome variable and covariates that are available in the data or can be engineered from the data.
Example covariates are crash hour, borough, number of vehicles involved, etc. Interpret your results.


```{python}
import statsmodels.formula.api as smf

mod = smf.logit("death ~ hour_int + borough", data=jan22).fit()
```

##

```{python}
mod.summary()
```

# Question 8

## 8a: Aggregate the data to the zip-code level


```{python}
jan22["zip_code_str"] = jan22["zip_code"].astype(str)
jan22["zip_code_str"] 
```

##

```{python}
jan22["zip_code_str"].str.split(".").str.get(1).value_counts()
```

##

```{python}
jan22["zip_code_str"].str.len().value_counts()
```


## 


```{python}
income20 = pd.read_csv("data/acs_data/ACSST5Y2020.S1903_data_with_overlays_2022-04-25T213110.csv")
```

## 8b: Connect with the census data at the zip-code level.

# Question 9

## Visualize ~~and model~~ the count of crashes at the zip-code level


```{python}
jan22["zip_code_str"].value_counts()
```

##


```{python}
size_by_zip = jan22.groupby(["zip_code_str"]).size()
```


```{python}
size_by_zip_df = pd.DataFrame(size_by_zip, columns=["count"]).reset_index()
size_by_zip_df = size_by_zip_df.loc[size_by_zip_df.zip_code_str != "nan"]
```

##

```{python}
size_by_zip_df.describe()
```


##

```{python}
from plotnine import geom_bar, coord_flip
ggplot(size_by_zip_df, aes(x="zip_code_str", y="count")) + geom_bar(stat="identity") + coord_flip()
```

##


```{python}
size_by_zip_df_sub = size_by_zip_df.loc[size_by_zip_df["count"] > 38].sort_values("count", ascending=False)

order_list = size_by_zip_df_sub.index.to_list()

zip_cat = pd.Categorical(size_by_zip_df_sub['zip_code_str'], categories=order_list)

size_by_zip_df_sub = size_by_zip_df_sub.assign(zip_cat = zip_cat)

(ggplot(size_by_zip_df_sub, aes(x="zip_cat", y="count")) + geom_bar(stat="identity") + coord_flip())
```
